---
layout: post
title: "[ 사이드 프로젝트 ] 약국은 휴일에도? -2-"
description: 공휴일 운영 약국을 지도로 검색 할 수 있는 사이드 프로젝트의 제작기 -2-
comments: true
tags: Python, Selenium
---

> Side 프로젝트 기록글 -2-

# 내가 크롤링 하려는 사이트는 어느 종류일까!

사이드 프로젝트를 진행하기 위해 휴일지킴이약국 사이트의 정보를 모두 가져와야 했다.
\
\
크롤링을 하기 전, 크롤링을 하려는 타겟 사이트를 크게 두가지로 나눌 수 있는데,

1. 도메인에 query/path parameter 으로 정보를 넘기면, 해당 정보에 맞게 출력을 해 주는 사이트. 
    ![naver-query](https://user-images.githubusercontent.com/25953981/103478404-d038fd00-4e09-11eb-952b-2ae0333b43a3.png)
    *검색하려는 단어인 "약국"을 query param 으로 넘긴다. 이 주소를 복사해서 다른 곳에 붙여넣어도 동일한 결과를 얻을 수 있다*

2. 동적으로 구성되어 있어 도메인 정보 변경 없이 페이지를 동적으로 업데이트 하는 사이트.
    ![pharmacy-query](https://user-images.githubusercontent.com/25953981/103478406-d333ed80-4e09-11eb-9e39-f34fc001f950.png)
    *주소는 search_result.asp 페이지로 고정되어 있고, 사용자의 행위에 따라 동적으로 페이지를 업데이트 한다*

전자의 경우에는 도메인에 내가 원하는 정보를 parameter 으로 입력하면 rest api 를 전송하는 것만으로 원하는 정보를 가져올 수 있기 때문에 클로링이 수월한 반면,\
후자는 특정 도메인에 들어가서 사용자가 직접 행위(클릭, form 입력 등)하는 것을 동일하게 해 주어야 원하는 정보를 얻을 수 있기 때문에 전자보다 크롤링 하기가 어렵다.
\
\
크롤링을 하려는 공공사이트가 전자이길 간절히 빌었으나, 레거시 사이트에 rest api 가 있을리 없지. 후자였다.\
오히려 좋다, 이 기회에 동적 사이트도 한번 크롤링 해 보자

![no-way](https://user-images.githubusercontent.com/25953981/103478662-9832b980-4e0b-11eb-8a4c-22275b190e87.png){: width="35%" height="35%"}


# Python 을 이용하여 동적페이지를 크롤링 해 보자

### Selenium 라이브러리

Python 에 마침 내가 원하는 라이브러리가 이미 존재했다.\
크롬 브라우저를 가상으로 띄워 사용자가 직접 사용하는 것처럼 작동시킬 수 있는 **Selenium** 라이브러리다.


![selenium-logo](https://user-images.githubusercontent.com/25953981/103478931-5d318580-4e0d-11eb-9a74-c30b1056f33d.png){: width="75%" height="75%"}
Selenium 라이브러리를 사용하면, 크롬 브라우저와 해당 브라우저를 컨트롤 할 수있는 웹드라이버만 설치하면 파이썬 코드를 통해 브라우저와 동적인 상호작용을 할 수 있다.
\
\
Selenium 을 통해 할수 있는 것을 크게 나열해 보자면,

- 기본적인 브라우저 동작 ( 앞으로 가기, 뒤로가기, 종료하기 )
- 페이지 내 WebElement 를 여러 기준으로 찾기 ( tag, id, name, css name .. etc)
- WebElement 와 상호작용 하기 ( click, pull-down menu fill, input form fill, .. etc)
- WebElement 의 정보 가져오기 ( inner html, outer htlm, tag info .. etc)

\
등등이 있다.\
내가 생각했던 거의 대부분의 액션이 모두 가능했다.
\
자세한 사용법은 [Selenium 공식 사이트](https://www.selenium.dev)와 구글에 검색해보면 많은 레퍼런스가 있다.

### 휴일지킴이 약국 사이트에 적용해보자

휴일지킴이 약국에서 원하는 정보를 얻기 위해서는 아래와 같은 과정이 필요했다.

1. 사이트 접속
2. 상단 메뉴중 "휴일지킴이약국" 선택
3. 날짜, 시간, 지역 선택
    ![select-date](https://user-images.githubusercontent.com/25953981/103479734-07f87280-4e13-11eb-87fd-0857014e9b20.png)
4. 결과로 나온 약국 정보 테이블 읽어오고, 이를 모든 페이지에 적용
    ![result-1](https://user-images.githubusercontent.com/25953981/103479735-08910900-4e13-11eb-8ad0-43f46cfdc125.png)
    ![result-2](https://user-images.githubusercontent.com/25953981/103479737-09c23600-4e13-11eb-97d1-e737f4c303c7.png)
5. 3번 으로 돌아가 모든 지역에서 반복

해당 과정을 Selenium 을 통해 반복하면, 우리가 원하는 약국 정보들을 모두 크롤링 해올 수 있다.\
(중간에 겪었던 문제점들은 노가다에 가깝기 때문에 생략하겠다.)

![query-result](https://user-images.githubusercontent.com/25953981/103479807-8ce38c00-4e13-11eb-9d12-4905d362e823.png)
*성공적으로 약국 데이터를 모두 가져왔다!*

크롤링을 위한 코드는 이 [링크](https://github.com/HVHO/holiday-pharmacy/tree/main/crawling)에 가면 볼 수 있다.


### 끝날때 까지 끝난게 아니다

아직 몇가지 해결되지 않은 문제점이 존재한다.
- 크롤링 코드가 잘못되어 정보가 누락될 경우
- **이미 폐업한 약국 정보가 들어가 있을 경우**
- 약국의 실제 운영 시간과 다를 경우

나는 토이프로젝트로 만드는 프로덕트이기 때문에 정보는 해당 공공사이트에 의존할 수 밖에 없다.\
공공사이트의 정보가 잘못되었을 경우 내 프로덕트에 그대로 반영되기 때문에, 최소한의 검증이 필요하다 생각했다.\
따라서 이후 kakao map api 와 연동하여 kakao map에 검색되지 않을 경우 invalid 한 데이터로 처리할 예정이다.
\
\
\
\
다음 게시글에서는 크롤링한 정보들을 저장할 AWS RDS DB를 만들고 연동하는 것을 기록할 예정이다.
